{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redframelbx/datascience/blob/main/machine%20learning/ML4DS_SvML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d84081-99c3-4fb7-9769-57a47b599eb6",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c9d84081-99c3-4fb7-9769-57a47b599eb6"
      },
      "source": [
        "<center><img src=\"https://lh3.googleusercontent.com/drive-viewer/AITFw-w3wIpyrbycg-wmuThEMA0kKfsNLaRX59iSQvjQawHZtoXIO3DfiR3GDf8YpHNjvBRnbQhMmgmIlzbbQB8QuZWRfvgkVw=s1600\" width=800spx ></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9be115e-ad2e-41f6-a0c5-b7abf48aff02",
      "metadata": {
        "id": "f9be115e-ad2e-41f6-a0c5-b7abf48aff02"
      },
      "source": [
        "# Supervised Machine Learning (Classification)\n",
        "<p>Classification is a process of finding a model that able to describe and distinguish data classes and concepts. The process typically involve training and testing with labelled data (class of the data is known).</p>\n",
        "\n",
        "<center><img src=\"https://lh5.googleusercontent.com/aGi5M4wtDWkQFGvw3ukvWmo5TEvd4kXOjjAE3hILhlYpiGKo0bgvTM96GfaMWr57hZo=w2400\" width=600px></center>\n",
        "<br>\n",
        "\n",
        "In this notebook, we will use `scikit-learn` Python library to\n",
        "- implement different machine learning methods for classification,\n",
        "- generate performance measurement reporting,\n",
        "- built-in datasets,\n",
        "- cross validations, train-test data split\n",
        "\n",
        "Make sure you have installed the library, or else install the library using the following command: <br>\n",
        "\n",
        "`pip install scikit-learn`\n",
        "\n",
        "<hr>\n",
        "\n",
        "## <span style='color:blue'>Case: Classification of Iris flower species</span>\n",
        "<img src='https://storage.googleapis.com/kaggle-datasets-images/17860/23404/efadfebe925588a27d94d61be1d376d3/dataset-cover.jpg?t=2018-03-22-16-10-55'>\n",
        "\n",
        "The Iris dataset can be obtained within the `scikit-learn` library\n",
        "\n",
        "### <span style='color:blue'>To import the dataset:</span>\n",
        "1. Load the `datasets` module from the `scikit-learn` library using the command: `from sklearn import datasets`\n",
        "2. Load the iris data set using the `load_iris()` function and assign to a variable called `iris`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "da8b4732-0ff4-4c03-a918-106b05610a65",
      "metadata": {
        "tags": [],
        "id": "da8b4732-0ff4-4c03-a918-106b05610a65"
      },
      "outputs": [],
      "source": [
        "# your code here to load the iris dataset according to the instruction above\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d799ef-dfd4-44f7-b7b1-7bb60f96bec3",
      "metadata": {
        "id": "55d799ef-dfd4-44f7-b7b1-7bb60f96bec3"
      },
      "source": [
        "### <span style='color:blue'>To explore the dataset:</span>\n",
        "1. You can use:\n",
        "<br>`dir(iris)` shows the attributes of the iris datasets.<br> `iris.data.shape` shows the shape of the data.<br>\n",
        "`iris.target_names` shows the classes that we want to classify.<br>\n",
        "`iris.feature_names` shows the name of features that we are training.<br>\n",
        "`iris.data` to get access the actual data values<br>\n",
        "`iris.target` to get access of the target labels for each data sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "35f2e312-4a8f-4686-abb8-67f5dc980606",
      "metadata": {
        "tags": [],
        "id": "35f2e312-4a8f-4686-abb8-67f5dc980606",
        "outputId": "359702f4-0bd7-4408-9826-cb5b7071b7d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DESCR',\n",
              " 'data',\n",
              " 'data_module',\n",
              " 'feature_names',\n",
              " 'filename',\n",
              " 'frame',\n",
              " 'target',\n",
              " 'target_names']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# your code here\n",
        "dir(iris)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.data.shape"
      ],
      "metadata": {
        "id": "nqZffCmWq0yO",
        "outputId": "4b892e4c-e203-4998-ebf5-5430d1cf0520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nqZffCmWq0yO",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target_names"
      ],
      "metadata": {
        "id": "v1g61JMPq8IL",
        "outputId": "7dc3cc6e-a34a-463e-97f1-7f60252db974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "v1g61JMPq8IL",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.feature_names"
      ],
      "metadata": {
        "id": "23BHyuOXrDqy",
        "outputId": "10ef9554-6a7e-4427-af4a-a92993f13c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "23BHyuOXrDqy",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.data"
      ],
      "metadata": {
        "id": "bKtivyDPq8Gr",
        "outputId": "5b6cc118-b74a-4a22-9168-788156e8f7f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bKtivyDPq8Gr",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target"
      ],
      "metadata": {
        "id": "hz061Y2LrQUy",
        "outputId": "901700f2-710b-465f-a31f-51e51846c4e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hz061Y2LrQUy",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7edb394a-3c4d-490d-a4a8-a846e08e76b7",
      "metadata": {
        "id": "7edb394a-3c4d-490d-a4a8-a846e08e76b7"
      },
      "source": [
        "### <span style='color:blue'>To prepare the data</span>\n",
        "1. create a variable `data` to store the iris data\n",
        "2. create a variable `target` to store the iris target labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46da4c32-465e-4765-8fed-77ba774eabae",
      "metadata": {
        "tags": [],
        "id": "46da4c32-465e-4765-8fed-77ba774eabae"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = iris.data\n",
        "target = iris.target"
      ],
      "metadata": {
        "id": "RRhaE4rurZrW"
      },
      "id": "RRhaE4rurZrW",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7b9a3d59-a6a8-43e5-bf22-097b04564a2d",
      "metadata": {
        "id": "7b9a3d59-a6a8-43e5-bf22-097b04564a2d"
      },
      "source": [
        "### <span style='color:blue'>To do data splitting</span>\n",
        "1. Load the `model_selection` module from the `scikit-learn` library\n",
        "2. Then split the data into train and test set using the `train_test_split()` function. This function will return 4 variables, which are train data, test data, train labels, test labels respectively. The input parameters for the function is as follows: `train_test_split( data, labels. test_size=0.2, random_state=1 )` where `test_size` refers to the percentage of the testing set (0.2 --> 20% test 80% train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "74b29aa9-0e6b-468d-8279-a6d9b3887cbd",
      "metadata": {
        "tags": [],
        "id": "74b29aa9-0e6b-468d-8279-a6d9b3887cbd"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "from sklearn import model_selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbcd8e41-93ea-441c-9b1b-5e47560bc78b",
      "metadata": {
        "id": "cbcd8e41-93ea-441c-9b1b-5e47560bc78b"
      },
      "source": [
        "Now with the dataset is ready, we will go through few of the supervised machine learning methods and create the classification models to classify iris species."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4741c1d-77ce-413c-addf-1da3bb2a0e25",
      "metadata": {
        "id": "a4741c1d-77ce-413c-addf-1da3bb2a0e25"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## <span style='color:darkred'>K-Nearest Neighbours (KNN)</span>\n",
        "\n",
        "Steps:\n",
        "1. Import library to use K-Nearest Neighbours using command: `from sklearn.neighbors import KNeighborsClassifier`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fab273b3-ac83-43c5-ad90-f27ff68e5676",
      "metadata": {
        "tags": [],
        "id": "fab273b3-ac83-43c5-ad90-f27ff68e5676"
      },
      "outputs": [],
      "source": [
        "## Your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1d1ed70-ae01-42ef-99c5-f2144eee8e46",
      "metadata": {
        "id": "e1d1ed70-ae01-42ef-99c5-f2144eee8e46"
      },
      "source": [
        "2. Initialize the model. Need to specify the number of neighbors to 3. It's always recommended to use odd number that is larger than 1. Then assign to a variable. Example: `knn_model = KNeighborsClassifier(n_neighbors=3)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e090b8-26af-48d4-b325-3167faeaafe2",
      "metadata": {
        "tags": [],
        "id": "b1e090b8-26af-48d4-b325-3167faeaafe2"
      },
      "outputs": [],
      "source": [
        "## Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3845daf5-e8f2-4729-9816-aa2a421aa902",
      "metadata": {
        "id": "3845daf5-e8f2-4729-9816-aa2a421aa902"
      },
      "source": [
        "3. Train model using training set. This can be done using the `fit()` function and pass in the train data and train labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "763ea434-690b-4d76-bd61-c18a777cc39f",
      "metadata": {
        "tags": [],
        "id": "763ea434-690b-4d76-bd61-c18a777cc39f"
      },
      "outputs": [],
      "source": [
        "## Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be95881e-39c8-4e80-9602-7e3a4c454a8d",
      "metadata": {
        "id": "be95881e-39c8-4e80-9602-7e3a4c454a8d"
      },
      "source": [
        "4. Test the trained model with testing set using the `predict()` and pass in the test data. Store the prediction results into a variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2d9082-fc71-48ee-8068-f1e153e35f3c",
      "metadata": {
        "tags": [],
        "id": "cd2d9082-fc71-48ee-8068-f1e153e35f3c"
      },
      "outputs": [],
      "source": [
        "## Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d95ad3b-8e49-482a-b2a6-056675edfa97",
      "metadata": {
        "id": "9d95ad3b-8e49-482a-b2a6-056675edfa97"
      },
      "source": [
        "5. Evaluate the predictions using `metrics` module in `scikit-learn` library. First load the library using `from sklearn import metrics`\n",
        "6. Then can use<br> `confusion_matrix(prediction, test_labels)` to generate the confusion matrix based on the prediction and real test labels. <br> `accuracy_score(prediction, test_labels)` to get the accuracy of the predictions.<br> ** there are many different metrics available, can refer to https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c63402e-640e-465f-aa28-f80ea81f51d4",
      "metadata": {
        "tags": [],
        "id": "8c63402e-640e-465f-aa28-f80ea81f51d4"
      },
      "outputs": [],
      "source": [
        "## Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "344dca22-3a9b-4992-94fe-3274a02e3979",
      "metadata": {
        "tags": [],
        "id": "344dca22-3a9b-4992-94fe-3274a02e3979"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## <span style='color:darkred'>Decision Trees</span>\n",
        "\n",
        "Steps:\n",
        "1. Import library to use Decision Tree using command: `from sklearn.tree import DecisionTreeClassifier`\n",
        "2. Initialize the model. Example: `dt_model = DecisionTreeClassifier(criterion='entropy', random_state=123)`\n",
        "3. Train model using training set. This can be done using the `fit()` function and pass in the train data and train labels.\n",
        "4. Test the trained model with testing set using the `predict()` and pass in the test data. Store the prediction results into a variable.\n",
        "5. Evaluate the predictions using `metrics` module in `scikit-learn` library. First load the library using `from sklearn import metrics`\n",
        "6. Then can use<br> `confusion_matrix(prediction, test_labels)` to generate the confusion matrix based on the prediction and real test labels. <br> `accuracy_score(prediction, test_labels)` to get the accuracy of the predictions.<br> ** there are many different metrics available, can refer to https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "| Parameters | Default | Description |\n",
        "| -------- | -------- | -------- |\n",
        "| `criterion` | 'entropy' | Evaluate feature importance. 'entropy' algorithm is based on Information theory which is a method to quantify information in a message. <br>It is used to quantify the information of the data to make decision and split the node. |\n",
        "| `min_samples_leaf` | 1 | Minimum number of sample(s) to qualify as leaf node |\n",
        "| `min_samples_split` | 2 | Minimum number of sample(s) to qualify for internal node split |\n",
        "| `splitter` | 'best' | Method used by the model to make decision when splitting. 'best' method will tell the model to consider feature with highest importance |\n",
        "| `random_state` | 0 | Seed to generate random number by the model. Will effect any randomness from the model |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df1dafb1-f97c-48a3-9814-582038bddf7d",
      "metadata": {
        "tags": [],
        "id": "df1dafb1-f97c-48a3-9814-582038bddf7d"
      },
      "outputs": [],
      "source": [
        "## Your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52cc5343-3b95-4c20-bad6-905152d3a461",
      "metadata": {
        "id": "52cc5343-3b95-4c20-bad6-905152d3a461"
      },
      "source": [
        "#### Visualizing the decision tree\n",
        "Decision tree is one of the simplest model that can be visualized using the `plot_tree` module in `scikit-learn` library and `matplotlib` library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10096637-5bd2-42d7-a78a-006fd7bffa6d",
      "metadata": {
        "id": "10096637-5bd2-42d7-a78a-006fd7bffa6d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "def view_tree(classifier):\n",
        "    fig, axes = plt.subplots(nrows=1,ncols=1,figsize=(4,4), dpi=150) #change dpi to resize image\n",
        "    tree_view = plot_tree(classifier, feature_names=iris.feature_names,\n",
        "              class_names=iris.target_names, ax=axes, filled=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272304c2-95ee-4c44-b60d-7e33002dbbc8",
      "metadata": {
        "tags": [],
        "id": "272304c2-95ee-4c44-b60d-7e33002dbbc8"
      },
      "outputs": [],
      "source": [
        "## Try to use the view_tree function above with your decision tree model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b465e1b9-8374-4071-a79c-b9fe39b71dcf",
      "metadata": {
        "id": "b465e1b9-8374-4071-a79c-b9fe39b71dcf"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## <span style='color:darkred'>Random Forest</span>\n",
        "Steps:\n",
        "1. Import library to use Random Forest using command: `from sklearn.ensemble import RandomForestClassifier`\n",
        "2. Initialize the model. Example: `rf_model = RandomForestClassifier(n_estimators=100)`\n",
        "3. Train model using training set. This can be done using the `fit()` function and pass in the train data and train labels.\n",
        "4. Test the trained model with testing set using the `predict()` and pass in the test data. Store the prediction results into a variable.\n",
        "5. Evaluate the predictions using `metrics` module in `scikit-learn` library. First load the library using `from sklearn import metrics`\n",
        "6. Then can use<br> `confusion_matrix(prediction, test_labels)` to generate the confusion matrix based on the prediction and real test labels. <br> `accuracy_score(prediction, test_labels)` to get the accuracy of the predictions.<br> ** there are many different metrics available, can refer to https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "\n",
        "| Parameters | Default | Description |\n",
        "| -------- | -------- | -------- |\n",
        "| `bootstrap` | `True` | Evaluate feature importance. 'entropy' algorithm is based on Information theory which is a method to quantify information in a message. <br>It is used to quantify the information of the data to make decision and split the node. |\n",
        "| `max_features` | 'auto' | Minimum number of sample(s) to qualify as leaf node |\n",
        "| `min_samples_leaf` | 1 | Minimum number of sample(s) to qualify for internal node split |\n",
        "| `min_samples_split` | 2 | Method used by the model to make decision when splitting. 'best' method will tell the model to consider feature with highest importance |\n",
        "| `n_estimators` | 10 | Seed to generate random number by the model. Will effect any randomness from the model |\n",
        "| `verbose` | 0 | Seed to generate random number by the model. Will effect any randomness from the model |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6f383f5-a058-4cb4-b1b7-abfcc632776d",
      "metadata": {
        "tags": [],
        "id": "b6f383f5-a058-4cb4-b1b7-abfcc632776d"
      },
      "outputs": [],
      "source": [
        "## Your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26a5e3cc-785b-4d5d-b26e-d75e8fbe7bdc",
      "metadata": {
        "id": "26a5e3cc-785b-4d5d-b26e-d75e8fbe7bdc"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## <span style='color:darkred'>Support Vector Machine</span>\n",
        "Steps:\n",
        "1. Import library to use SVM using command: `from sklearn.svm import SVC`\n",
        "2. Initialize the model. Example: `svm_model = SVC(kernel='linear', gamma='auto')`\n",
        "3. Train model using training set. This can be done using the `fit()` function and pass in the train data and train labels.\n",
        "4. Test the trained model with testing set using the `predict()` and pass in the test data. Store the prediction results into a variable.\n",
        "5. Evaluate the predictions using `metrics` module in `scikit-learn` library. First load the library using `from sklearn import metrics`\n",
        "6. Then can use<br> `confusion_matrix(prediction, test_labels)` to generate the confusion matrix based on the prediction and real test labels. <br> `accuracy_score(prediction, test_labels)` to get the accuracy of the predictions.<br> ** there are many different metrics available, can refer to https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13056c55-bfb3-4b1d-a142-946dce0db150",
      "metadata": {
        "tags": [],
        "id": "13056c55-bfb3-4b1d-a142-946dce0db150"
      },
      "outputs": [],
      "source": [
        "## Your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b961bb81-e442-498a-b43d-92791d23343c",
      "metadata": {
        "id": "b961bb81-e442-498a-b43d-92791d23343c"
      },
      "source": [
        "SVM can use 'kernel trick' for high dimensional and non-linear data, there are several types of kernel can be used:\n",
        "- linear kernel with `kernel='linear'`\n",
        "- radial basis function (RBF) kernel with `kernel='rbf'`\n",
        "- Sigmoid kernel with `kernel='sigmoid'`\n",
        "- Polynomial kernel with `kernel='poly'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b83582-bf94-4482-835d-f5d95ce13bc6",
      "metadata": {
        "tags": [],
        "id": "44b83582-bf94-4482-835d-f5d95ce13bc6"
      },
      "outputs": [],
      "source": [
        "## Try train model with different kernel\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41bd97b2-4434-4ab8-8bad-b1fac635697d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "tags": [],
        "id": "41bd97b2-4434-4ab8-8bad-b1fac635697d"
      },
      "source": [
        "###\n",
        "<center><span style=\"color:#510104\">© 2023 UTM Big Data Centre. All Rights Reserved</span></center>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}